{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework: Deep Jazz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from music21 import stream, midi, tempo, note\n",
    "\n",
    "from grammar import unparse_grammar\n",
    "from preprocess import get_musical_data, get_corpus_data\n",
    "\n",
    "from qa import prune_grammar, prune_notes, clean_up_notes\n",
    "from generator import __sample, __generate_grammar, __predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_epochs = 128  # default\n",
    "data_fn = 'midi/' + 'original_metheny.mid'  # 'And Then I Knew' by Pat Metheny\n",
    "out_fn = 'midi/' 'deepjazz_on_metheny_' + str(N_epochs) + '_epochs.midi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 193\n",
      "total # of values: 78\n"
     ]
    }
   ],
   "source": [
    "max_len = 20\n",
    "max_tries = 1000\n",
    "diversity = 0.5\n",
    "\n",
    "# musical settings\n",
    "bpm = 130\n",
    "\n",
    "# get data\n",
    "chords, abstract_grammars = get_musical_data(data_fn)\n",
    "corpus, values, val_indices, indices_val = get_corpus_data(abstract_grammars)\n",
    "print('corpus length:', len(corpus))\n",
    "print('total # of values:', len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<music21.instrument.Piano Piano>,\n",
       " <music21.tempo.MetronomeMark Quarter=112.0>,\n",
       " <music21.key.Key of G major>,\n",
       " <music21.meter.TimeSignature 4/4>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "def get_keras_model(max_len, N_values):\n",
    "    # build a 2 stacked LSTM\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences=True, input_shape=(max_len, N_values)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(128, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(N_values))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"553pt\" viewBox=\"0.00 0.00 318.00 553.00\" width=\"318pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 549)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-549 314,-549 314,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140447931075776 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140447931075776</title>\n",
       "<polygon fill=\"none\" points=\"0,-498.5 0,-544.5 310,-544.5 310,-498.5 0,-498.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"79\" y=\"-517.8\">lstm_3_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"158,-498.5 158,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"186\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"158,-521.5 214,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"186\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"214,-498.5 214,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262\" y=\"-529.3\">(None, 20, 78)</text>\n",
       "<polyline fill=\"none\" points=\"214,-521.5 310,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262\" y=\"-506.3\">(None, 20, 78)</text>\n",
       "</g>\n",
       "<!-- 140447931943344 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140447931943344</title>\n",
       "<polygon fill=\"none\" points=\"26.5,-415.5 26.5,-461.5 283.5,-461.5 283.5,-415.5 26.5,-415.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"75.5\" y=\"-434.8\">lstm_3: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"124.5,-415.5 124.5,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152.5\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"124.5,-438.5 180.5,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152.5\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"180.5,-415.5 180.5,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232\" y=\"-446.3\">(None, 20, 78)</text>\n",
       "<polyline fill=\"none\" points=\"180.5,-438.5 283.5,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232\" y=\"-423.3\">(None, 20, 128)</text>\n",
       "</g>\n",
       "<!-- 140447931075776&#45;&gt;140447931943344 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140447931075776-&gt;140447931943344</title>\n",
       "<path d=\"M155,-498.366C155,-490.152 155,-480.658 155,-471.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"158.5,-471.607 155,-461.607 151.5,-471.607 158.5,-471.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140447931073032 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140447931073032</title>\n",
       "<polygon fill=\"none\" points=\"12.5,-332.5 12.5,-378.5 297.5,-378.5 297.5,-332.5 12.5,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"75.5\" y=\"-351.8\">dropout_3: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"138.5,-332.5 138.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"138.5,-355.5 194.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"194.5,-332.5 194.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-363.3\">(None, 20, 128)</text>\n",
       "<polyline fill=\"none\" points=\"194.5,-355.5 297.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-340.3\">(None, 20, 128)</text>\n",
       "</g>\n",
       "<!-- 140447931943344&#45;&gt;140447931073032 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140447931943344-&gt;140447931073032</title>\n",
       "<path d=\"M155,-415.366C155,-407.152 155,-397.658 155,-388.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"158.5,-388.607 155,-378.607 151.5,-388.607 158.5,-388.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140447931075104 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140447931075104</title>\n",
       "<polygon fill=\"none\" points=\"26.5,-249.5 26.5,-295.5 283.5,-295.5 283.5,-249.5 26.5,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"75.5\" y=\"-268.8\">lstm_4: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"124.5,-249.5 124.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"124.5,-272.5 180.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"180.5,-249.5 180.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232\" y=\"-280.3\">(None, 20, 128)</text>\n",
       "<polyline fill=\"none\" points=\"180.5,-272.5 283.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232\" y=\"-257.3\">(None, 128)</text>\n",
       "</g>\n",
       "<!-- 140447931073032&#45;&gt;140447931075104 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140447931073032-&gt;140447931075104</title>\n",
       "<path d=\"M155,-332.366C155,-324.152 155,-314.658 155,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"158.5,-305.607 155,-295.607 151.5,-305.607 158.5,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140447929667200 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140447929667200</title>\n",
       "<polygon fill=\"none\" points=\"22.5,-166.5 22.5,-212.5 287.5,-212.5 287.5,-166.5 22.5,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85.5\" y=\"-185.8\">dropout_4: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"148.5,-166.5 148.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"176.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"148.5,-189.5 204.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"176.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"204.5,-166.5 204.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-197.3\">(None, 128)</text>\n",
       "<polyline fill=\"none\" points=\"204.5,-189.5 287.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-174.3\">(None, 128)</text>\n",
       "</g>\n",
       "<!-- 140447931075104&#45;&gt;140447929667200 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140447931075104-&gt;140447929667200</title>\n",
       "<path d=\"M155,-249.366C155,-241.152 155,-231.658 155,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"158.5,-222.607 155,-212.607 151.5,-222.607 158.5,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140447927429552 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140447927429552</title>\n",
       "<polygon fill=\"none\" points=\"34.5,-83.5 34.5,-129.5 275.5,-129.5 275.5,-83.5 34.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85.5\" y=\"-102.8\">dense_2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"136.5,-83.5 136.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"164.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"136.5,-106.5 192.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"164.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"192.5,-83.5 192.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"234\" y=\"-114.3\">(None, 128)</text>\n",
       "<polyline fill=\"none\" points=\"192.5,-106.5 275.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"234\" y=\"-91.3\">(None, 78)</text>\n",
       "</g>\n",
       "<!-- 140447929667200&#45;&gt;140447927429552 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140447929667200-&gt;140447927429552</title>\n",
       "<path d=\"M155,-166.366C155,-158.152 155,-148.658 155,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"158.5,-139.607 155,-129.607 151.5,-139.607 158.5,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140447923871696 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140447923871696</title>\n",
       "<polygon fill=\"none\" points=\"12.5,-0.5 12.5,-46.5 297.5,-46.5 297.5,-0.5 12.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"88.5\" y=\"-19.8\">activation_2: Activation</text>\n",
       "<polyline fill=\"none\" points=\"164.5,-0.5 164.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"192.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"164.5,-23.5 220.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"192.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"220.5,-0.5 220.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"259\" y=\"-31.3\">(None, 78)</text>\n",
       "<polyline fill=\"none\" points=\"220.5,-23.5 297.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"259\" y=\"-8.3\">(None, 78)</text>\n",
       "</g>\n",
       "<!-- 140447927429552&#45;&gt;140447923871696 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140447927429552-&gt;140447923871696</title>\n",
       "<path d=\"M155,-83.3664C155,-75.1516 155,-65.6579 155,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"158.5,-56.6068 155,-46.6068 151.5,-56.6069 158.5,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(get_keras_model(20, 78), show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace previous model with equivalent in prettytensor or tf.slim\n",
    "\n",
    "Try to make you code as compact as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import prettytensor as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# С prettytensor ничего не получилось =(\n",
    "\n",
    "class PTModel:\n",
    "    def __init__(self, max_len, N_values):\n",
    "        self.max_len = max_len\n",
    "        self.N_values = N_values\n",
    "        self.session = tf.Session()\n",
    "        \n",
    "    def _create_model(self, phase, batch_size):\n",
    "        self.inputs = self.__reshape_data(self.input_placeholder, \n",
    "                                          per_example_length=self.N_values)\n",
    "        self.labels = self.__reshape_data(\n",
    "            tf.reshape(\n",
    "                tf.tile(\n",
    "                    self.label_placeholder, [1, self.max_len]\n",
    "                ), [batch_size, self.max_len, self.N_values]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        lstm = self.inputs.cleave_sequence(self.max_len)\n",
    "        lstm = lstm.sequence_lstm(num_units=128)\n",
    "        \n",
    "        return lstm.squash_sequence()\\\n",
    "            .dropout(keep_prob=0.8, phase=phase)\\\n",
    "            .softmax_classifier(self.N_values, labels)\n",
    "\n",
    "    def __reshape_data(self, tensor, per_example_length=1):\n",
    "        dims = [1, 0]\n",
    "        for i in range(2, tensor.get_shape().ndims):\n",
    "            dims.append(i)\n",
    "        return pt.wrap(tf.transpose(tensor, dims)).reshape([-1, per_example_length])\n",
    "    \n",
    "    def __gen_batch(self, X, y, batch_size):\n",
    "        idxs = np.random.randint(low=0, high=X.shape[0] - 1, size=batch_size)\n",
    "        return X[idxs], y[idxs]\n",
    "        \n",
    "    def fit(self, X, y, batch_size, epochs):\n",
    "        self.input_placeholder = tf.placeholder(tf.float32, [batch_size, self.max_len, self.N_values])\n",
    "        self.label_placeholder = tf.placeholder(tf.float32, [batch_size, self.N_values])\n",
    "        \n",
    "        with tf.variable_scope('model'):\n",
    "            self.train_model = self._create_model(pt.Phase.train, batch_size)\n",
    "            \n",
    "        with tf.variable_scope('model', reuse=True):\n",
    "            self.test_model = self._create_model(pt.Phase.test, batch_size)\n",
    "            \n",
    "        accuracy = self.test_model.softmax.evaluate_classifier(\n",
    "            self.labels,\n",
    "            phase=pt.Phase.test\n",
    "        )\n",
    "            \n",
    "        optimizer = tf.train.RMSPropOptimizer(learning_rate=0.1)\n",
    "        train_op = pt.apply_optimizer(optimizer, losses=[self.model.loss])\n",
    "        \n",
    "        runner = pt.train.Runner(save_path='pretty_tensor_model/')\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            X_batch, y_batch = self.__gen_batch(X, y, batch_size)\n",
    "            runner.train_model(\n",
    "                train_op,\n",
    "                self.train_model.loss,\n",
    "                epochs,\n",
    "                feed_vars=(self.input_placeholder,\n",
    "                           self.label_placeholder),\n",
    "                feed_data=pt.train.feed_numpy(batch_size, X_batch, y_batch)\n",
    "            )\n",
    "\n",
    "            classification_accuracy = runner.evaluate_model(\n",
    "                accuracy,\n",
    "                epochs,\n",
    "                feed_vars=(self.input_placeholder, self.label_placeholder),\n",
    "                feed_data=pt.train.feed_numpy(batch_size, X_batch, y_batch)\n",
    "            )\n",
    "\n",
    "            print('Accuracy after epoch %d: %g%%' % (epoch + 1, classification_accuracy * 100))\n",
    "                \n",
    "    def predict(self, x, verbose):\n",
    "        y_pred = self.test_model.softmax(self.input_placeholder)\n",
    "        y_cls = tf.argmax(y_pred, dimension=1)\n",
    "        \n",
    "        y = session.run(y_cls, {\n",
    "            self.input_placeholder: x\n",
    "        })\n",
    "        \n",
    "        return y\n",
    "        \n",
    "    \n",
    "    def close_session(self):\n",
    "        self.session.close()\n",
    "        \n",
    "\n",
    "def get_pretty_tensor_model(max_len, N_values):    \n",
    "    return PTModel(max_len=max_len, N_values=N_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.contrib.rnn import DropoutWrapper\n",
    "\n",
    "class SlimModel:\n",
    "    def __init__(self, max_len, N_values):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.input_placeholder = tf.placeholder(tf.float32, shape=(None, max_len, N_values))\n",
    "        self.label_placeholder = tf.placeholder(tf.float32, shape=(None, N_values))\n",
    "        \n",
    "        with tf.variable_scope('level1'):\n",
    "            cell = tf.nn.rnn_cell.LSTMCell(128, initializer=tf.random_normal_initializer(0.0, 0.3))\n",
    "            dropout = DropoutWrapper(cell, output_keep_prob=0.8) \n",
    "            outputs, last_state = tf.nn.dynamic_rnn(dropout, self.input_placeholder, dtype=tf.float32)\n",
    "        \n",
    "        with tf.variable_scope('level2'):\n",
    "            cell2 = tf.nn.rnn_cell.LSTMCell(128, initializer=tf.random_normal_initializer(0.0, 0.3))\n",
    "            dropout2 = DropoutWrapper(cell2, output_keep_prob=0.8) \n",
    "            outputs2, last_state2 = tf.nn.dynamic_rnn(dropout2, outputs, dtype=tf.float32)\n",
    "\n",
    "        print(outputs2.shape)\n",
    "        print(last_state2[1].shape)\n",
    "        \n",
    "        logits = slim.fully_connected(inputs=last_state2[1], num_outputs=N_values)\n",
    "        print(logits.shape)\n",
    "        self.prediction = slim.softmax(logits)\n",
    "\n",
    "        self.loss = tf.losses.softmax_cross_entropy(self.label_placeholder, logits)\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(learning_rate=0.1).minimize(self.loss)\n",
    "        \n",
    "    def __gen_batch(self, X, y, batch_size):\n",
    "        idxs = np.random.randint(low=0, high=X.shape[0] - 1, size=batch_size)\n",
    "        return X[idxs], y[idxs]\n",
    "    \n",
    "    def fit(self, X, y, batch_size, epochs):\n",
    "        self.session = tf.Session()\n",
    "        self.session.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            X_batch, y_batch = self.__gen_batch(X, y, batch_size)\n",
    "            _, loss = self.session.run([self.optimizer, self.loss], \n",
    "                                      feed_dict = {self.input_placeholder: X_batch, \n",
    "                                                   self.label_placeholder: y_batch})\n",
    "            print('iter ' + str(i) + ' loss ' + str(loss))\n",
    "    \n",
    "    def predict(self, x, verbose):\n",
    "        return self.session.run(self.prediction, feed_dict={self.input_placeholder: x})\n",
    "    \n",
    "    def close_session(self):\n",
    "        self.session.close()\n",
    "    \n",
    "# sess = tf.InteractiveSession()\n",
    "def get_slim_model(max_len, N_values):\n",
    "    return SlimModel(max_len, N_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_model = get_slim_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "''' Build a 2-layer LSTM from a training corpus '''\n",
    "\n",
    "\n",
    "def build_model(corpus, val_indices, max_len, N_epochs=128):\n",
    "    # number of different values or words in corpus\n",
    "    N_values = len(set(corpus))\n",
    "\n",
    "    # cut the corpus into semi-redundant sequences of max_len values\n",
    "    step = 3\n",
    "    sentences = []\n",
    "    next_values = []\n",
    "    for i in range(0, len(corpus) - max_len, step):\n",
    "        sentences.append(corpus[i: i + max_len])\n",
    "        next_values.append(corpus[i + max_len])\n",
    "    print('nb sequences:', len(sentences))\n",
    "\n",
    "    # transform data into binary matrices\n",
    "    X = np.zeros((len(sentences), max_len, N_values), dtype=np.bool)\n",
    "    y = np.zeros((len(sentences), N_values), dtype=np.bool)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for t, val in enumerate(sentence):\n",
    "            X[i, t, val_indices[val]] = 1\n",
    "        y[i, val_indices[next_values[i]]] = 1\n",
    "\n",
    "    model = get_model(max_len, N_values)\n",
    "    model.fit(X, y, batch_size=128, epochs=N_epochs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model\n",
      "nb sequences: 58\n",
      "(?, 20, 128)\n",
      "(?, 128)\n",
      "(?, 78)\n",
      "iter 0 loss 4.34111\n",
      "iter 1 loss 4.36152\n",
      "iter 2 loss 4.33655\n",
      "iter 3 loss 4.28994\n",
      "iter 4 loss 4.2301\n",
      "iter 5 loss 4.2486\n",
      "iter 6 loss 4.26232\n",
      "iter 7 loss 4.13477\n",
      "iter 8 loss 4.2238\n",
      "iter 9 loss 4.13329\n",
      "iter 10 loss 3.98396\n",
      "iter 11 loss 3.9848\n",
      "iter 12 loss 4.01923\n",
      "iter 13 loss 4.04778\n",
      "iter 14 loss 4.03389\n",
      "iter 15 loss 3.94675\n",
      "iter 16 loss 3.95551\n",
      "iter 17 loss 3.95086\n",
      "iter 18 loss 3.94859\n",
      "iter 19 loss 3.87457\n",
      "iter 20 loss 3.77185\n",
      "iter 21 loss 4.02761\n",
      "iter 22 loss 3.99141\n",
      "iter 23 loss 3.8659\n",
      "iter 24 loss 3.91312\n",
      "iter 25 loss 3.74386\n",
      "iter 26 loss 3.80837\n",
      "iter 27 loss 3.76174\n",
      "iter 28 loss 3.94871\n",
      "iter 29 loss 3.69873\n",
      "iter 30 loss 3.85534\n",
      "iter 31 loss 3.60351\n",
      "iter 32 loss 3.7645\n",
      "iter 33 loss 3.56515\n",
      "iter 34 loss 3.63093\n",
      "iter 35 loss 3.55265\n",
      "iter 36 loss 3.4523\n",
      "iter 37 loss 4.07496\n",
      "iter 38 loss 3.95496\n",
      "iter 39 loss 3.6997\n",
      "iter 40 loss 3.83975\n",
      "iter 41 loss 3.80945\n",
      "iter 42 loss 3.64628\n",
      "iter 43 loss 3.71903\n",
      "iter 44 loss 3.57037\n",
      "iter 45 loss 3.95143\n",
      "iter 46 loss 3.68405\n",
      "iter 47 loss 3.73552\n",
      "iter 48 loss 4.01357\n",
      "iter 49 loss 4.15215\n",
      "iter 50 loss 3.90222\n",
      "iter 51 loss 3.80621\n",
      "iter 52 loss 3.87711\n",
      "iter 53 loss 3.91644\n",
      "iter 54 loss 4.04814\n",
      "iter 55 loss 4.00652\n",
      "iter 56 loss 4.05552\n",
      "iter 57 loss 3.82994\n",
      "iter 58 loss 3.81133\n",
      "iter 59 loss 4.09259\n",
      "iter 60 loss 4.00505\n",
      "iter 61 loss 4.05513\n",
      "iter 62 loss 4.40163\n",
      "iter 63 loss 4.0525\n",
      "iter 64 loss 3.69563\n",
      "iter 65 loss 3.97088\n",
      "iter 66 loss 3.66823\n",
      "iter 67 loss 3.71547\n",
      "iter 68 loss 3.70312\n",
      "iter 69 loss 3.83706\n",
      "iter 70 loss 4.27974\n",
      "iter 71 loss 4.21651\n",
      "iter 72 loss 4.03625\n",
      "iter 73 loss 4.00458\n",
      "iter 74 loss 3.6995\n",
      "iter 75 loss 3.57688\n",
      "iter 76 loss 3.5115\n",
      "iter 77 loss 4.71638\n",
      "iter 78 loss 3.86579\n",
      "iter 79 loss 3.6621\n",
      "iter 80 loss 3.76621\n",
      "iter 81 loss 3.74587\n",
      "iter 82 loss 3.79486\n",
      "iter 83 loss 4.16747\n",
      "iter 84 loss 3.67036\n",
      "iter 85 loss 3.51905\n",
      "iter 86 loss 3.48781\n",
      "iter 87 loss 3.75624\n",
      "iter 88 loss 3.23658\n",
      "iter 89 loss 3.35917\n",
      "iter 90 loss 3.29272\n",
      "iter 91 loss 3.39426\n",
      "iter 92 loss 3.22694\n",
      "iter 93 loss 2.99066\n",
      "iter 94 loss 3.31838\n",
      "iter 95 loss 3.6137\n",
      "iter 96 loss 3.16235\n",
      "iter 97 loss 3.05657\n",
      "iter 98 loss 2.61253\n",
      "iter 99 loss 2.95786\n",
      "iter 100 loss 2.72123\n",
      "iter 101 loss 3.15743\n",
      "iter 102 loss 2.87856\n",
      "iter 103 loss 2.51343\n",
      "iter 104 loss 2.19758\n",
      "iter 105 loss 1.90547\n",
      "iter 106 loss 1.78064\n",
      "iter 107 loss 2.61065\n",
      "iter 108 loss 2.07277\n",
      "iter 109 loss 1.57837\n",
      "iter 110 loss 1.35618\n",
      "iter 111 loss 1.5276\n",
      "iter 112 loss 1.27919\n",
      "iter 113 loss 1.33887\n",
      "iter 114 loss 1.65332\n",
      "iter 115 loss 1.39267\n",
      "iter 116 loss 2.74238\n",
      "iter 117 loss 5.27769\n",
      "iter 118 loss 3.96804\n",
      "iter 119 loss 5.2639\n",
      "iter 120 loss 3.66901\n",
      "iter 121 loss 4.78944\n",
      "iter 122 loss 6.06513\n",
      "iter 123 loss 3.93488\n",
      "iter 124 loss 5.80679\n",
      "iter 125 loss 4.61082\n",
      "iter 126 loss 5.39018\n",
      "iter 127 loss 4.40102\n",
      "model has been built\n",
      "After pruning: 13 notes\n",
      "After pruning: 15 notes\n",
      "After pruning: 12 notes\n",
      "After pruning: 14 notes\n",
      "After pruning: 13 notes\n",
      "After pruning: 16 notes\n",
      "After pruning: 14 notes\n",
      "After pruning: 15 notes\n",
      "After pruning: 13 notes\n",
      "After pruning: 12 notes\n",
      "After pruning: 12 notes\n",
      "After pruning: 13 notes\n",
      "After pruning: 14 notes\n",
      "After pruning: 13 notes\n",
      "After pruning: 14 notes\n",
      "After pruning: 14 notes\n",
      "After pruning: 14 notes\n",
      "After pruning: 16 notes\n",
      "saving to file\n"
     ]
    }
   ],
   "source": [
    "print('building model')\n",
    "# build model\n",
    "model = build_model(corpus=corpus, val_indices=val_indices,\n",
    "                         max_len=max_len, N_epochs=N_epochs)\n",
    "print('model has been built')\n",
    "\n",
    "# set up audio stream\n",
    "out_stream = stream.Stream()\n",
    "\n",
    "# generation loop\n",
    "curr_offset = 0.0\n",
    "loopEnd = len(chords)\n",
    "for loopIndex in range(1, loopEnd):\n",
    "    # get chords from file\n",
    "    curr_chords = stream.Voice()\n",
    "    for j in chords[loopIndex]:\n",
    "        curr_chords.insert((j.offset % 4), j)\n",
    "\n",
    "    # generate grammar\n",
    "    curr_grammar = __generate_grammar(model=model, corpus=corpus,\n",
    "                                      abstract_grammars=abstract_grammars,\n",
    "                                      values=values, val_indices=val_indices,\n",
    "                                      indices_val=indices_val,\n",
    "                                      max_len=max_len, max_tries=max_tries,\n",
    "                                      diversity=diversity)\n",
    "\n",
    "    curr_grammar = curr_grammar.replace(' A', ' C').replace(' X', ' C')\n",
    "\n",
    "    # Pruning #1: smoothing measure\n",
    "    curr_grammar = prune_grammar(curr_grammar)\n",
    "\n",
    "    # Get notes from grammar and chords\n",
    "    curr_notes = unparse_grammar(curr_grammar, curr_chords)\n",
    "\n",
    "    # Pruning #2: removing repeated and too close together notes\n",
    "    curr_notes = prune_notes(curr_notes)\n",
    "\n",
    "    # quality assurance: clean up notes\n",
    "    curr_notes = clean_up_notes(curr_notes)\n",
    "\n",
    "    # print # of notes in curr_notes\n",
    "    print('After pruning: %s notes' % (len([i for i in curr_notes\n",
    "                                            if isinstance(i, note.Note)])))\n",
    "\n",
    "    # insert into the output stream\n",
    "    for m in curr_notes:\n",
    "        out_stream.insert(curr_offset + m.offset, m)\n",
    "    for mc in curr_chords:\n",
    "        out_stream.insert(curr_offset + mc.offset, mc)\n",
    "\n",
    "    curr_offset += 4.0\n",
    "\n",
    "out_stream.insert(0.0, tempo.MetronomeMark(number=bpm))\n",
    "\n",
    "# Play the final stream through output (see 'play' lambda function above)\n",
    "play = lambda x: midi.realtime.StreamPlayer(x).play()\n",
    "play(out_stream)\n",
    "\n",
    "# save stream\n",
    "print('saving to file')\n",
    "mf = midi.translate.streamToMidiFile(out_stream)\n",
    "mf.open(out_fn, 'wb')\n",
    "mf.write()\n",
    "mf.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play generated sample using any midi player\n",
    "\n",
    "Under linux I prefer timidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Requested buffer size 32768, fragment size 8192',\n",
       " \"ALSA pcm 'default' set buffer size 32768, period size 8192 bytes\",\n",
       " 'Playing midi/deepjazz_on_metheny_128_epochs.midi',\n",
       " 'MIDI file: midi/deepjazz_on_metheny_128_epochs.midi',\n",
       " 'Format: 1  Tracks: 1  Divisions: 1024',\n",
       " 'Sequence: ',\n",
       " 'Playing time: ~38 seconds',\n",
       " 'Notes cut: 0',\n",
       " 'Notes lost totally: 0']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!! timidity midi/deepjazz_on_metheny_128_epochs.midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.close_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
